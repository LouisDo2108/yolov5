YOLOv5 ðŸš€ v7.0-72-g064365d Python-3.8.15 torch-1.12.1 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11017MiB)

Fusing layers... 
Model summary: 157 layers, 7026307 parameters, 0 gradients, 15.8 GFLOPs
YOLOv5 ðŸš€ v7.0-72-g064365d Python-3.8.15 torch-1.12.1 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11017MiB)

Fusing layers... 
Model summary: 157 layers, 7026307 parameters, 0 gradients, 15.8 GFLOPs
Epoch 0/99, current lr=0.0001
Copied best model weights!
train loss: 1.025611, val loss: 0.656650, f1-score-micro: 80.53, f1-score-weighted: 67.82
----------
Epoch 1/99, current lr=0.0001
train loss: 0.685707, val loss: 0.671187, f1-score-micro: 62.70, f1-score-weighted: 60.68
----------
Epoch 2/99, current lr=0.0001
Copied best model weights!
train loss: 0.630860, val loss: 0.627073, f1-score-micro: 78.00, f1-score-weighted: 68.22
----------
Epoch 3/99, current lr=0.0001
Copied best model weights!
train loss: 0.559160, val loss: 0.618822, f1-score-micro: 79.66, f1-score-weighted: 69.61
----------
Epoch 4/99, current lr=0.0001
Copied best model weights!
train loss: 0.473909, val loss: 0.571160, f1-score-micro: 80.30, f1-score-weighted: 70.40
----------
Epoch 5/99, current lr=0.0001
Copied best model weights!
train loss: 0.360964, val loss: 0.430183, f1-score-micro: 86.84, f1-score-weighted: 86.24
----------
Epoch 6/99, current lr=0.0001
Copied best model weights!
train loss: 0.259552, val loss: 0.413969, f1-score-micro: 84.84, f1-score-weighted: 85.26
----------
Epoch 7/99, current lr=0.0001
Copied best model weights!
train loss: 0.205539, val loss: 0.384869, f1-score-micro: 86.62, f1-score-weighted: 86.01
----------
Epoch 8/99, current lr=0.0001
Copied best model weights!
train loss: 0.156698, val loss: 0.367218, f1-score-micro: 87.55, f1-score-weighted: 87.62
----------
Epoch 9/99, current lr=0.0001
train loss: 0.111776, val loss: 0.399796, f1-score-micro: 84.64, f1-score-weighted: 85.10
----------
Epoch 10/99, current lr=0.0001
train loss: 0.081911, val loss: 0.428749, f1-score-micro: 85.72, f1-score-weighted: 85.43
----------
Epoch 11/99, current lr=0.0001
train loss: 0.055647, val loss: 0.492542, f1-score-micro: 85.55, f1-score-weighted: 85.61
----------
Epoch 12/99, current lr=0.0001
train loss: 0.052089, val loss: 0.516346, f1-score-micro: 86.46, f1-score-weighted: 86.63
----------
Epoch 13/99, current lr=0.0001
train loss: 0.039337, val loss: 0.652389, f1-score-micro: 82.46, f1-score-weighted: 82.59
----------
Epoch 14/99, current lr=0.0001
train loss: 0.021316, val loss: 0.695420, f1-score-micro: 84.64, f1-score-weighted: 84.81
----------
Epoch 15/99, current lr=0.0001
train loss: 0.030023, val loss: 0.838814, f1-score-micro: 84.09, f1-score-weighted: 84.45
----------
Epoch 16/99, current lr=0.0001
train loss: 0.006162, val loss: 0.753581, f1-score-micro: 85.62, f1-score-weighted: 85.81
----------
Epoch 17/99, current lr=0.0001
train loss: 0.005824, val loss: 0.760163, f1-score-micro: 84.34, f1-score-weighted: 84.55
----------
Epoch 18/99, current lr=0.0001
train loss: 0.005838, val loss: 0.998322, f1-score-micro: 86.09, f1-score-weighted: 86.31
----------
Epoch 19/99, current lr=0.0001
train loss: 0.002532, val loss: 0.691361, f1-score-micro: 84.04, f1-score-weighted: 83.96
----------
Epoch 20/99, current lr=0.0001
train loss: 0.000993, val loss: 0.947850, f1-score-micro: 86.11, f1-score-weighted: 86.25
----------
Epoch 21/99, current lr=0.0001
train loss: 0.000733, val loss: 0.946675, f1-score-micro: 84.93, f1-score-weighted: 85.05
----------
Epoch 22/99, current lr=0.0001
train loss: 0.000466, val loss: 0.996233, f1-score-micro: 84.75, f1-score-weighted: 84.89
----------
Epoch 23/99, current lr=0.0001
train loss: 0.000387, val loss: 1.023881, f1-score-micro: 85.88, f1-score-weighted: 86.08
----------
Epoch 24/99, current lr=0.0001
train loss: 0.000298, val loss: 1.078249, f1-score-micro: 83.03, f1-score-weighted: 83.13
----------
Epoch 25/99, current lr=0.0001
train loss: 0.000245, val loss: 1.129766, f1-score-micro: 85.88, f1-score-weighted: 85.98
----------
Epoch 26/99, current lr=0.0001
train loss: 0.000219, val loss: 1.026597, f1-score-micro: 86.54, f1-score-weighted: 86.75
----------
Epoch 27/99, current lr=0.0001
train loss: 0.000186, val loss: 1.008211, f1-score-micro: 84.58, f1-score-weighted: 84.54
----------
Epoch 28/99, current lr=0.0001
train loss: 0.000162, val loss: 0.988923, f1-score-micro: 85.77, f1-score-weighted: 85.99
----------
Epoch 29/99, current lr=0.0001
Loading best model weights!
train loss: 0.000136, val loss: 1.136121, f1-score-micro: 83.68, f1-score-weighted: 83.73
----------
Epoch 30/99, current lr=5e-05
train loss: 0.119697, val loss: 0.419662, f1-score-micro: 82.96, f1-score-weighted: 83.50
----------
Epoch 31/99, current lr=5e-05
train loss: 0.135286, val loss: 0.466119, f1-score-micro: 84.56, f1-score-weighted: 85.16
----------
Epoch 32/99, current lr=5e-05
train loss: 0.117359, val loss: 0.411117, f1-score-micro: 84.68, f1-score-weighted: 85.07
----------
Epoch 33/99, current lr=5e-05
train loss: 0.086668, val loss: 0.426775, f1-score-micro: 86.58, f1-score-weighted: 86.81
----------
Epoch 34/99, current lr=5e-05
train loss: 0.054301, val loss: 0.469976, f1-score-micro: 86.64, f1-score-weighted: 86.10
----------
Epoch 35/99, current lr=5e-05
train loss: 0.042143, val loss: 0.502613, f1-score-micro: 85.99, f1-score-weighted: 85.18
----------
Epoch 36/99, current lr=5e-05
train loss: 0.037310, val loss: 0.458047, f1-score-micro: 88.72, f1-score-weighted: 88.75
----------
Epoch 37/99, current lr=5e-05
train loss: 0.026305, val loss: 0.611583, f1-score-micro: 86.80, f1-score-weighted: 87.31
----------
Epoch 38/99, current lr=5e-05
train loss: 0.028129, val loss: 0.592272, f1-score-micro: 88.84, f1-score-weighted: 88.47
----------
Epoch 39/99, current lr=5e-05
train loss: 0.022650, val loss: 0.669073, f1-score-micro: 84.49, f1-score-weighted: 84.35
----------
Epoch 40/99, current lr=5e-05
train loss: 0.010859, val loss: 0.741622, f1-score-micro: 85.41, f1-score-weighted: 85.35
----------
Epoch 41/99, current lr=5e-05
train loss: 0.028086, val loss: 0.685509, f1-score-micro: 86.79, f1-score-weighted: 87.01
----------
Epoch 42/99, current lr=5e-05
train loss: 0.023526, val loss: 0.814081, f1-score-micro: 86.14, f1-score-weighted: 86.49
----------
Epoch 43/99, current lr=5e-05
train loss: 0.014418, val loss: 0.834692, f1-score-micro: 85.83, f1-score-weighted: 85.99
----------
Epoch 44/99, current lr=5e-05
train loss: 0.005996, val loss: 0.714594, f1-score-micro: 84.67, f1-score-weighted: 84.67
----------
Epoch 45/99, current lr=5e-05
train loss: 0.004439, val loss: 0.779681, f1-score-micro: 84.72, f1-score-weighted: 84.80
----------
Epoch 46/99, current lr=5e-05
train loss: 0.002314, val loss: 0.712056, f1-score-micro: 86.10, f1-score-weighted: 86.41
----------
Epoch 47/99, current lr=5e-05
train loss: 0.001526, val loss: 0.742175, f1-score-micro: 86.11, f1-score-weighted: 86.15
----------
Epoch 48/99, current lr=5e-05
train loss: 0.001433, val loss: 0.896249, f1-score-micro: 85.74, f1-score-weighted: 85.95
----------
Epoch 49/99, current lr=5e-05
train loss: 0.001417, val loss: 0.763588, f1-score-micro: 86.93, f1-score-weighted: 86.94
----------
Epoch 50/99, current lr=5e-05
Loading best model weights!
train loss: 0.000807, val loss: 0.846911, f1-score-micro: 85.55, f1-score-weighted: 85.76
----------
Epoch 51/99, current lr=2.5e-05
Copied best model weights!
train loss: 0.108848, val loss: 0.305647, f1-score-micro: 88.69, f1-score-weighted: 88.46
----------
Epoch 52/99, current lr=2.5e-05
Copied best model weights!
train loss: 0.085210, val loss: 0.296099, f1-score-micro: 89.99, f1-score-weighted: 89.90
----------
Epoch 53/99, current lr=2.5e-05
train loss: 0.080918, val loss: 0.363248, f1-score-micro: 85.44, f1-score-weighted: 85.59
----------
Epoch 54/99, current lr=2.5e-05
train loss: 0.082946, val loss: 0.388636, f1-score-micro: 88.63, f1-score-weighted: 88.56
----------
Epoch 55/99, current lr=2.5e-05
train loss: 0.072483, val loss: 0.421649, f1-score-micro: 86.19, f1-score-weighted: 86.06
----------
Epoch 56/99, current lr=2.5e-05
train loss: 0.056338, val loss: 0.368065, f1-score-micro: 86.93, f1-score-weighted: 86.33
----------
Epoch 57/99, current lr=2.5e-05
train loss: 0.056436, val loss: 0.357611, f1-score-micro: 87.55, f1-score-weighted: 87.59
----------
Epoch 58/99, current lr=2.5e-05
train loss: 0.040934, val loss: 0.543906, f1-score-micro: 87.68, f1-score-weighted: 87.77
----------
Epoch 59/99, current lr=2.5e-05
train loss: 0.040458, val loss: 0.509703, f1-score-micro: 87.52, f1-score-weighted: 87.62
----------
Epoch 60/99, current lr=2.5e-05
train loss: 0.028131, val loss: 0.565956, f1-score-micro: 85.29, f1-score-weighted: 85.53
----------
Epoch 61/99, current lr=2.5e-05
train loss: 0.025089, val loss: 0.620573, f1-score-micro: 86.67, f1-score-weighted: 86.67
----------
Epoch 62/99, current lr=2.5e-05
train loss: 0.021586, val loss: 0.641614, f1-score-micro: 87.39, f1-score-weighted: 87.59
----------
Epoch 63/99, current lr=2.5e-05
train loss: 0.018363, val loss: 0.614788, f1-score-micro: 86.91, f1-score-weighted: 86.97
----------
Epoch 64/99, current lr=2.5e-05
train loss: 0.015023, val loss: 0.674790, f1-score-micro: 85.68, f1-score-weighted: 85.93
----------
Epoch 65/99, current lr=2.5e-05
train loss: 0.013133, val loss: 0.695988, f1-score-micro: 86.17, f1-score-weighted: 86.29
----------
Epoch 66/99, current lr=2.5e-05
train loss: 0.010461, val loss: 0.770498, f1-score-micro: 84.78, f1-score-weighted: 84.95
----------
Epoch 67/99, current lr=2.5e-05
train loss: 0.009035, val loss: 0.714429, f1-score-micro: 86.03, f1-score-weighted: 86.15
----------
Epoch 68/99, current lr=2.5e-05
train loss: 0.006947, val loss: 0.796492, f1-score-micro: 85.75, f1-score-weighted: 86.03
----------
Epoch 69/99, current lr=2.5e-05
train loss: 0.006472, val loss: 0.692285, f1-score-micro: 88.16, f1-score-weighted: 88.22
----------
Epoch 70/99, current lr=2.5e-05
train loss: 0.004101, val loss: 0.805935, f1-score-micro: 85.61, f1-score-weighted: 85.83
----------
Epoch 71/99, current lr=2.5e-05
train loss: 0.005980, val loss: 0.819743, f1-score-micro: 84.54, f1-score-weighted: 84.72
----------
Epoch 72/99, current lr=2.5e-05
train loss: 0.003975, val loss: 0.815212, f1-score-micro: 87.19, f1-score-weighted: 87.37
----------
Epoch 73/99, current lr=2.5e-05
Loading best model weights!
train loss: 0.003990, val loss: 0.905678, f1-score-micro: 85.22, f1-score-weighted: 85.63
----------
Epoch 74/99, current lr=1.25e-05
train loss: 0.086927, val loss: 0.344144, f1-score-micro: 87.31, f1-score-weighted: 87.30
----------
Epoch 75/99, current lr=1.25e-05
train loss: 0.083192, val loss: 0.312741, f1-score-micro: 87.27, f1-score-weighted: 86.97
----------
Epoch 76/99, current lr=1.25e-05
train loss: 0.074217, val loss: 0.385417, f1-score-micro: 86.00, f1-score-weighted: 86.08
----------
Epoch 77/99, current lr=1.25e-05
train loss: 0.068758, val loss: 0.383812, f1-score-micro: 87.56, f1-score-weighted: 87.56
----------
Epoch 78/99, current lr=1.25e-05
train loss: 0.065526, val loss: 0.405828, f1-score-micro: 87.62, f1-score-weighted: 87.43
----------
Epoch 79/99, current lr=1.25e-05
train loss: 0.064217, val loss: 0.418338, f1-score-micro: 87.18, f1-score-weighted: 87.29
----------
Epoch 80/99, current lr=1.25e-05
train loss: 0.059456, val loss: 0.388710, f1-score-micro: 88.46, f1-score-weighted: 88.76
----------
Epoch 81/99, current lr=1.25e-05
train loss: 0.046524, val loss: 0.443162, f1-score-micro: 87.16, f1-score-weighted: 87.34
----------
Epoch 82/99, current lr=1.25e-05
train loss: 0.048936, val loss: 0.454545, f1-score-micro: 88.41, f1-score-weighted: 88.59
----------
Epoch 83/99, current lr=1.25e-05
train loss: 0.042765, val loss: 0.481211, f1-score-micro: 86.69, f1-score-weighted: 86.97
----------
Epoch 84/99, current lr=1.25e-05
train loss: 0.040721, val loss: 0.518124, f1-score-micro: 85.29, f1-score-weighted: 85.40
----------
Epoch 85/99, current lr=1.25e-05
train loss: 0.029175, val loss: 0.486611, f1-score-micro: 86.96, f1-score-weighted: 87.13
----------
Epoch 86/99, current lr=1.25e-05
train loss: 0.036344, val loss: 0.488539, f1-score-micro: 87.47, f1-score-weighted: 87.47
----------
Epoch 87/99, current lr=1.25e-05
train loss: 0.029567, val loss: 0.544729, f1-score-micro: 87.35, f1-score-weighted: 87.56
----------
Epoch 88/99, current lr=1.25e-05
train loss: 0.030573, val loss: 0.583400, f1-score-micro: 87.37, f1-score-weighted: 87.45
----------
Epoch 89/99, current lr=1.25e-05
train loss: 0.031505, val loss: 0.585523, f1-score-micro: 85.40, f1-score-weighted: 85.54
----------
Epoch 90/99, current lr=1.25e-05
train loss: 0.021948, val loss: 0.605701, f1-score-micro: 86.07, f1-score-weighted: 86.24
----------
Epoch 91/99, current lr=1.25e-05
train loss: 0.025307, val loss: 0.652128, f1-score-micro: 86.60, f1-score-weighted: 86.97
----------
Epoch 92/99, current lr=1.25e-05
train loss: 0.027872, val loss: 0.388292, f1-score-micro: 88.06, f1-score-weighted: 88.16
----------
Epoch 93/99, current lr=1.25e-05
train loss: 0.018776, val loss: 0.544461, f1-score-micro: 86.72, f1-score-weighted: 86.78
----------
Epoch 94/99, current lr=1.25e-05
Loading best model weights!
train loss: 0.012675, val loss: 0.639783, f1-score-micro: 85.99, f1-score-weighted: 86.28
----------
Epoch 95/99, current lr=6.25e-06
train loss: 0.081390, val loss: 0.351470, f1-score-micro: 87.84, f1-score-weighted: 87.82
----------
Epoch 96/99, current lr=6.25e-06
train loss: 0.078559, val loss: 0.335991, f1-score-micro: 87.41, f1-score-weighted: 87.28
----------
Epoch 97/99, current lr=6.25e-06
train loss: 0.077982, val loss: 0.340791, f1-score-micro: 90.04, f1-score-weighted: 90.17
----------
Epoch 98/99, current lr=6.25e-06
train loss: 0.074523, val loss: 0.368888, f1-score-micro: 87.92, f1-score-weighted: 87.80
----------
Epoch 99/99, current lr=6.25e-06
train loss: 0.063905, val loss: 0.384077, f1-score-micro: 87.15, f1-score-weighted: 86.99
----------
Epoch 00030: reducing learning rate of group 0 to 5.0000e-05.
Epoch 00051: reducing learning rate of group 0 to 2.5000e-05.
Epoch 00074: reducing learning rate of group 0 to 1.2500e-05.
Epoch 00095: reducing learning rate of group 0 to 6.2500e-06.
